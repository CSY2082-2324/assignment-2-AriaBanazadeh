{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importig all the libraries\n",
    "\n",
    "import os\n",
    "import gdown\n",
    "import tensorflow as tf\n",
    "from deepface.commons import functions\n",
    "from deepface.commons.logger import Logger\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "        Convolution2D,\n",
    "        ZeroPadding2D,\n",
    "        MaxPooling2D,\n",
    "        Flatten,\n",
    "        Dropout,\n",
    "        Activation,\n",
    "        Lambda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-Face Model\n",
    "def loadModel():\n",
    "    model = Sequential()\n",
    "    model.add(data_augmentation)\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(224, 224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.build((None, 224, 224, 3)) \n",
    "\n",
    "    model.load_weights(os.path.join(\"/kaggle/input\",\"aaazzzz\", \"vgg_face_weights.h5\"))\n",
    "\n",
    "    model_output = Flatten()(model.layers[-5].output)\n",
    "    model_output = Lambda(lambda x: K.l2_normalize(x, axis=1), name=\"norm_layer\")(\n",
    "        model_output\n",
    "    )\n",
    "\n",
    "    return Model(inputs=model.input, outputs=model_output)\n",
    "\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandomZoom(0.2),\n",
    "        layers.RandomTranslation(0.1, 0.1, fill_mode=\"nearest\", interpolation=\"bilinear\")\n",
    "    ]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
