{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importig all the libraries\n",
    "\n",
    "import os\n",
    "import gdown\n",
    "import tensorflow as tf\n",
    "from deepface.commons import functions\n",
    "from deepface.commons.logger import Logger\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "        Convolution2D,\n",
    "        ZeroPadding2D,\n",
    "        MaxPooling2D,\n",
    "        Flatten,\n",
    "        Dropout,\n",
    "        Activation,\n",
    "        Lambda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-Face Model\n",
    "def loadModel():\n",
    "    model = Sequential()\n",
    "    model.add(data_augmentation)\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(224, 224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.build((None, 224, 224, 3)) \n",
    "\n",
    "    model.load_weights(os.path.join(\"/kaggle/input\",\"aaazzzz\", \"vgg_face_weights.h5\"))\n",
    "\n",
    "    model_output = Flatten()(model.layers[-5].output)\n",
    "    model_output = Lambda(lambda x: K.l2_normalize(x, axis=1), name=\"norm_layer\")(\n",
    "        model_output\n",
    "    )\n",
    "\n",
    "    return Model(inputs=model.input, outputs=model_output)\n",
    "\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandomZoom(0.2),\n",
    "        layers.RandomTranslation(0.1, 0.1, fill_mode=\"nearest\", interpolation=\"bilinear\")\n",
    "    ]\n",
    ")\n",
    "#Pulling the celebrity faces dataset\n",
    "\n",
    "base_path = '/kaggle/input/celebrity-face-image-dataset/Celebrity Faces Dataset'\n",
    "folders = os.listdir(base_path)[:10]\n",
    "df = pa.DataFrame(\n",
    "    [\n",
    "        (os.path.join(base_path, folder, picture), folder[5:])\n",
    "        for folder in folders\n",
    "        for picture in os.listdir(os.path.join(base_path, folder))\n",
    "    ],\n",
    "    columns=['path', 'celebrity']\n",
    ").assign(celebrity_encoded=lambda x: LabelEncoder().fit_transform(x['celebrity']))\n",
    "folds = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(X=df['path'], y=df['celebrity_encoded']))\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def classification1 (train_embedding, test_embedding, train_labels, test_labels):\n",
    "    scaler = StandardScaler()\n",
    "    train_embedding = scaler.fit_transform(train_embedding)\n",
    "    test_embedding = scaler.transform(test_embedding)\n",
    "    pca = PCA(n_components=128)\n",
    "    train_embedding = pca.fit_transform(train_embedding)\n",
    "    test_embedding = pca.transform(test_embedding)\n",
    "    re = RandomForestClassifier(n_jobs = -1)\n",
    "    re.fit(train_embedding, train_labels)\n",
    "    predict  = re.predict(test_embedding)\n",
    "    return accuracy_score(test_labels, predict)\n",
    "\n",
    "def classification2 (train_embedding, test_embedding, train_labels, test_labels):\n",
    "    scaler = StandardScaler()\n",
    "    train_embedding = scaler.fit_transform(train_embedding)\n",
    "    test_embedding = scaler.transform(test_embedding)\n",
    "    pca = PCA(n_components=128)\n",
    "    train_embedding = pca.fit_transform(train_embedding)\n",
    "    test_embedding = pca.transform(test_embedding)\n",
    "    clf = SVC(C=5., gamma=0.001)\n",
    "    clf.fit(train_embedding, train_labels)\n",
    "    predict = clf.predict(test_embedding)\n",
    "    return accuracy_score(test_labels, predict)\n",
    "\n",
    "def classification3 (train_embedding, test_embedding, train_labels, test_labels):\n",
    "    re = RandomForestClassifier(n_jobs = -1)\n",
    "    re.fit(train_embedding, train_labels)\n",
    "    predict  = re.predict(test_embedding)\n",
    "    return accuracy_score(test_labels, predict)\n",
    "\n",
    "def classification4 (train_embedding, test_embedding, train_labels, test_labels):\n",
    "    xgb = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "    xgb.fit(train_embedding, train_labels)\n",
    "    predict = xgb.predict(test_embedding)\n",
    "    return accuracy_score(test_labels, predict)\n",
    "    \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def img_to_face(img):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.3, minNeighbors=5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    x, y, w, h = faces[0]\n",
    "    face_region = img[y:y+h, x:x+w]\n",
    "    face_region_rgb = cv2.cvtColor(face_region, cv2.COLOR_BGR2RGB)\n",
    "    return face_region_rgb\n",
    "\n",
    "def test_model(model_id):\n",
    "    print(\"Model - > VG\" )\n",
    "    answer = []\n",
    "    fold_number = 0\n",
    "    for fold in folds:\n",
    "        print(\"Fold -> \", fold_number)\n",
    "        train = df.iloc[fold[0]]\n",
    "        test = df.iloc[fold[1]]\n",
    "        train_labels = train[\"celebrity_encoded\"]\n",
    "        test_labels = test[\"celebrity_encoded\"]\n",
    "        \n",
    "        train_embedding=[]\n",
    "        test_embedding = []\n",
    "        \n",
    "        model = loadModel()\n",
    "\n",
    "        for counter, (index, img) in enumerate(train.iterrows()):\n",
    "            print(counter)\n",
    "            \n",
    "            imgg = img_to_face(cv2.imread(img['path']))\n",
    "            if imgg is None:\n",
    "                imgg = cv2.imread(img['path'])\n",
    "\n",
    "            imgg = cv2.resize(imgg, (224, 224))\n",
    "            imgg = np.expand_dims(imgg, axis=0)\n",
    "            imgg = imgg.astype('float64') / 255.0 \n",
    "            train_embedding.append( model.predict(imgg)[0, :])\n",
    "\n",
    "        print(len(test))\n",
    "        for counter, (index, img) in enumerate(test.iterrows()):\n",
    "            print(counter)\n",
    "            \n",
    "            imgg = img_to_face(cv2.imread(img['path']))\n",
    "            if imgg is None:\n",
    "                imgg = cv2.imread(img['path'])\n",
    "            imgg = cv2.resize(imgg, (224, 224))\n",
    "            imgg = imgg.astype('float64') / 255.0 \n",
    "            imgg = np.expand_dims(imgg, axis=0) \n",
    "            \n",
    "            test_embedding.append( model.predict(imgg)[0, :])\n",
    "        \n",
    "        answer.append([classification1(train_embedding, test_embedding, train_labels, test_labels), classification2(train_embedding, test_embedding, train_labels, test_labels),classification3(train_embedding, test_embedding, train_labels, test_labels),classification4(train_embedding, test_embedding, train_labels, test_labels)])\n",
    "        print(\"For this fold -> \", answer[fold_number])\n",
    "        fold_number = fold_number + 1\n",
    "    res1 = 0\n",
    "    res2 = 0\n",
    "    res3=0\n",
    "    res4=0\n",
    "    \n",
    "    print(res1, res2, res3, res4)\n",
    "    for i in range(fold_number):\n",
    "        res1 += answer[i][0]\n",
    "        res2 += answer[i][1]\n",
    "        res3 += answer[i][2]\n",
    "        res4 += answer[i][3]\n",
    "    return (res1 / fold_number, res2 / fold_number, res3/ fold_number, res4/foldernumber)\n",
    "\n",
    "def models_test():\n",
    "    for i in range(0,8):\n",
    "        ress = test_model(i)\n",
    "        print(\"For model -> \", \"vg\", \" The classification accuracy with rf + pca +ss -> \" , ress[0], \" accuracy with svc + pca + ss -> \", ress[1], \" accuracy with normal rf -> \", ress[2] , ' XGBOST=> ' , ress[3])\n",
    "    \n",
    "models_test()\n",
    "\n",
    "!PIP INSTALL ULTRALYTICS\n",
    "\n",
    "\n",
    "I have used the following methods.\n",
    "\n",
    "I have implemented YOLOV8 model stemmed from this Keras example[1,2],\n",
    "Used tf.data for input pipeline,\n",
    "I created txt file parser function,\n",
    "My Another Segmentation Projects\n",
    "Lung Segmentation UNet w/SeparableConv (Dice:0.93)\n",
    "Brain tumor/anomaly segmentation with Unet using TPU\n",
    "Brain tissue segmentation with Unet using TPU (Dice: 0.88)\n",
    "References\n",
    "https://keras.io/examples/vision/yolov8/\n",
    "Reis, D., Kupec, J., Hong, J., & Daoudi, A. (2023). Real-Time Flying Object Detection with YOLOv8 (Version 1). arXiv. https://doi.org/10.48550/ARXIV.2305.09972\n",
    "# Importing dependencies\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import keras_cv\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "GLOBAL_CLIPNORM = 10.0\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
    "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
    "Using TensorFlow backend\n",
    "Preprocessing\n",
    "# a function for converting txt file to list\n",
    "def parse_txt_annot(img_path, txt_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    w = int(img.shape[0])\n",
    "    h = int(img.shape[1])\n",
    "\n",
    "    file_label = open(txt_path, \"r\")\n",
    "    lines = file_label.read().split('\\n')\n",
    "    \n",
    "    boxes = []\n",
    "    classes = []\n",
    "    \n",
    "    for i in range(0, int(len(lines))):\n",
    "        objbud=lines[i].split(' ')\n",
    "        class_ = int(objbud[0])\n",
    "        \n",
    "        x1 = float(objbud[1])\n",
    "        y1 = float(objbud[2])\n",
    "        w1 = float(objbud[3])\n",
    "        h1 = float(objbud[4])\n",
    "        \n",
    "        xmin = int((x1*w) - (w1*w)/2.0)\n",
    "        ymin = int((y1*h) - (h1*h)/2.0)\n",
    "        xmax = int((x1*w) + (w1*w)/2.0)\n",
    "        ymax = int((y1*h) + (h1*h)/2.0)\n",
    "    \n",
    "        boxes.append([xmin ,ymin ,xmax ,ymax])\n",
    "        classes.append(class_)\n",
    "    \n",
    "    return img_path, classes, boxes\n",
    "\n",
    "\n",
    "# a function for creating file paths list \n",
    "def create_paths_list(path):\n",
    "    full_path = []\n",
    "    images = sorted(os.listdir(path))\n",
    "    \n",
    "    for i in images:\n",
    "        full_path.append(os.path.join(path, i))\n",
    "        \n",
    "    return full_path\n",
    "\n",
    "\n",
    "class_ids = ['apart_parking', 'blackbox', 'disabled_parking', 'etc', 'highpass', 'navigator']\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "# a function for creating a dict format of files\n",
    "def creating_files(img_files_paths, annot_files_paths):\n",
    "    \n",
    "    img_files = create_paths_list(img_files_paths)\n",
    "    annot_files = create_paths_list(annot_files_paths)\n",
    "    \n",
    "    image_paths = []\n",
    "    bbox = []\n",
    "    classes = []\n",
    "    \n",
    "    for i in range(0,len(img_files)):\n",
    "        image_path_, classes_, bbox_ = parse_txt_annot(img_files[i], annot_files[i])\n",
    "        image_paths.append(image_path_)\n",
    "        bbox.append(bbox_)\n",
    "        classes.append(classes_)\n",
    "        \n",
    "    image_paths = tf.ragged.constant(image_paths)\n",
    "    bbox = tf.ragged.constant(bbox)\n",
    "    classes = tf.ragged.constant(classes)\n",
    "    \n",
    "    return image_paths, classes, bbox\n",
    "# applying functions\n",
    "train_img_paths, train_classes, train_bboxes = creating_files('/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/train/images', \n",
    "                                                              '/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/train/labels')\n",
    "\n",
    "valid_img_paths, valid_classes, valid_bboxes = creating_files('/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/valid/images', \n",
    "                                                              '/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/valid/labels')\n",
    "\n",
    "test_img_paths, test_classes, test_bboxes = creating_files('/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/test/images', \n",
    "                                                           '/kaggle/input/disabled-people-sign-detection/disabled_sign_detection/test/labels')\n",
    "Creating Datasets\n",
    "# reading and resizing images\n",
    "def img_preprocessing(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.cast(img, tf.float32) \n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "resizing = keras_cv.layers.JitteredResize(\n",
    "    target_size=(640, 640),\n",
    "    scale_factor=(0.75, 1.3),\n",
    "    bounding_box_format=\"xyxy\")\n",
    "\n",
    "# loading dataset\n",
    "def load_ds(img_paths, classes, bbox):\n",
    "    img = img_preprocessing(img_paths)\n",
    "\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": bbox }\n",
    "    \n",
    "    return {\"images\": img, \"bounding_boxes\": bounding_boxes}\n",
    "\n",
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "# Creating dataset loaders and tf.datasets\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((train_img_paths, train_classes, train_bboxes))\n",
    "train_dataset = (train_loader\n",
    "                 .map(load_ds, num_parallel_calls = AUTO)\n",
    "                 .shuffle(BATCH_SIZE*10)\n",
    "                 .ragged_batch(BATCH_SIZE, drop_remainder = True)\n",
    "                 .map(resizing, num_parallel_calls = AUTO)\n",
    "                 .map(dict_to_tuple, num_parallel_calls = AUTO)\n",
    "                 .prefetch(AUTO))\n",
    "\n",
    "\n",
    "valid_loader = tf.data.Dataset.from_tensor_slices((valid_img_paths, valid_classes, valid_bboxes))\n",
    "valid_dataset = (valid_loader\n",
    "                 .map(load_ds, num_parallel_calls = AUTO)\n",
    "                 .ragged_batch(BATCH_SIZE, drop_remainder = True)\n",
    "                 .map(resizing, num_parallel_calls = AUTO)\n",
    "                 .map(dict_to_tuple, num_parallel_calls = AUTO)\n",
    "                 .prefetch(AUTO))\n",
    "\n",
    "\n",
    "test_loader = tf.data.Dataset.from_tensor_slices((test_img_paths, test_classes, test_bboxes))\n",
    "test_dataset = (test_loader\n",
    "                .map(load_ds, num_parallel_calls = AUTO)\n",
    "                .ragged_batch(BATCH_SIZE, drop_remainder = True)\n",
    "                .map(resizing, num_parallel_calls = AUTO)\n",
    "                .map(dict_to_tuple, num_parallel_calls = AUTO)\n",
    "                .prefetch(AUTO))\n",
    "# a function to visualize samples from a dataset\n",
    "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
    "    inputs = next(iter(inputs.take(1)))\n",
    "    images, bounding_boxes = inputs[0], inputs[1]\n",
    "    \n",
    "    keras_cv.visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=value_range,\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        y_true=bounding_boxes,\n",
    "        scale = 8,\n",
    "        font_scale = 0.8,\n",
    "        line_thickness=2,\n",
    "        dpi = 100,\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        class_mapping=class_mapping,\n",
    "        true_color = (192, 57, 43))\n",
    "# examples images and annotations from training daatset\n",
    "visualize_dataset(train_dataset, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=2, cols=2)\n",
    "\n",
    "YOLO V8 Model\n",
    "# creating pre-trained model backbone with coco weights\n",
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_m_backbone_coco\")\n",
    "Attaching 'config.json' from model 'keras/yolov8/keras/yolo_v8_m_backbone_coco/2' to your Kaggle notebook...\n",
    "Attaching 'config.json' from model 'keras/yolov8/keras/yolo_v8_m_backbone_coco/2' to your Kaggle notebook...\n",
    "Attaching 'model.weights.h5' from model 'keras/yolov8/keras/yolo_v8_m_backbone_coco/2' to your Kaggle notebook...\n",
    "/opt/conda/lib/python3.10/site-packages/keras_cv/src/models/backbones/backbone.py:44: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
    "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
    "/opt/conda/lib/python3.10/site-packages/keras_cv/src/models/backbones/backbone.py:44: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
    "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
    "YOLOV8_model = keras_cv.models.YOLOV8Detector(num_classes=len(class_mapping),\n",
    "                                              bounding_box_format=\"xyxy\",\n",
    "                                              backbone=backbone, fpn_depth=1 )\n",
    "\n",
    "optimizer = AdamW(learning_rate=0.001, weight_decay=0.004, global_clipnorm = GLOBAL_CLIPNORM)\n",
    "\n",
    "YOLOV8_model.compile(optimizer = optimizer, classification_loss = 'binary_crossentropy', box_loss = 'ciou')\n",
    "Training \n",
    "hist = YOLOV8_model.fit(train_dataset, validation_data = valid_dataset,  epochs = 80 )\n",
    "Training Results, Evaluation\n",
    "fig, axs = plt.subplots(1,3, figsize = (18,5), dpi = 130)\n",
    "\n",
    "axs[0].grid(linestyle=\"dashdot\")\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].plot(hist.history['loss'][1:])\n",
    "axs[0].plot(hist.history['val_loss'][1:])\n",
    "axs[0].legend([\"train\", \"validataion\"])\n",
    "\n",
    "axs[1].grid(linestyle=\"dashdot\")\n",
    "axs[1].set_title(\"Box Loss\")\n",
    "axs[1].plot(hist.history['box_loss'])\n",
    "axs[1].plot(hist.history['val_box_loss'])\n",
    "axs[1].legend([\"train\",  \"validataion\"])\n",
    "\n",
    "axs[2].grid(linestyle=\"dashdot\")\n",
    "axs[2].set_title(\"Class Loss\")\n",
    "axs[2].plot(hist.history['class_loss'][1:])\n",
    "axs[2].plot(hist.history['val_class_loss'][1:])\n",
    "axs[2].legend([\"train\",  \"validataion\"])\n",
    "<matplotlib.legend.Legend at 0x7cbe84c1afe0>\n",
    "\n",
    "Test Predictions\n",
    "def visualize_predict_detections(model, dataset, bounding_box_format):\n",
    "    images, y_true = next(iter(dataset.take(1)))\n",
    "        \n",
    "    y_pred = model.predict(images)\n",
    "    y_pred = keras_cv.bounding_box.to_ragged(y_pred)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
